{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y carga del dataset (sin rutas rigidas)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "csv_path = None\n",
    "for root, _, files in os.walk('.'):\n",
    "    if 'fallos_producto.csv' in files:\n",
    "        csv_path = os.path.join(root, 'fallos_producto.csv')\n",
    "        break\n",
    "if csv_path is None:\n",
    "    raise FileNotFoundError('fallos_producto.csv no encontrado')\n",
    "df_fallos = pd.read_csv(csv_path)\n",
    "df_fallos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcac66",
   "metadata": {},
   "source": [
    "Realiza un AED sobre el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fallos.info()\n",
    "df_fallos.head()\n",
    "df_fallos.isna().mean().sort_values(ascending=False).head(10)\n",
    "df_fallos['failure'].isna().value_counts(dropna=False)\n",
    "cat_cols = ['product_code', 'attribute_0', 'attribute_1']\n",
    "missing_cat = [c for c in cat_cols if c not in df_fallos.columns]\n",
    "missing_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0649af3d",
   "metadata": {},
   "source": [
    "Estadísticos iniciales. 0.2 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fallos.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc583ac",
   "metadata": {},
   "source": [
    "Distribuciones de las variables numéricas del conjunto de datos. 0.3 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fallos.select_dtypes(include='number').hist(bins=30, figsize=(12, 8))\n",
    "plt.suptitle('Distribuciones numericas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d7aa8",
   "metadata": {},
   "source": [
    "Matriz de correlación. 0.5 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a261187",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_fallos.select_dtypes(include='number').corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de correlacion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e5799",
   "metadata": {},
   "source": [
    "Realiza el preprocesamiento de datos de tu problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47691c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar labeled / unlabeled (failure NaN)\n",
    "df_labeled = df_fallos[df_fallos['failure'].notna()].copy()\n",
    "df_unlabeled = df_fallos[df_fallos['failure'].isna()].copy()\n",
    "\n",
    "# Features/target solo con labeled\n",
    "X_labeled = df_labeled.drop(columns=['failure'])\n",
    "y_labeled = df_labeled['failure'].astype(int)\n",
    "\n",
    "# Definir columnas categoricas y numericas\n",
    "cat_cols = ['product_code', 'attribute_0', 'attribute_1']\n",
    "num_cols = [c for c in X_labeled.columns if c not in cat_cols + ['id']]\n",
    "\n",
    "X_unlabeled = df_unlabeled.drop(columns=['failure'])\n",
    "\n",
    "# Asserts anti-leakage (labeled/unlabeled)\n",
    "assert df_unlabeled['failure'].isna().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b4a43",
   "metadata": {},
   "source": [
    "Reserva un conjunto de datos para validación y otro para testeo. 0.5 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split estratificado SOLO dentro de labeled\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_labeled, y_labeled, test_size=0.30, stratify=y_labeled, random_state=42\n",
    ")\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# Asserts anti-leakage obligatorios\n",
    "assert y_valid.notna().all() and y_test.notna().all()\n",
    "assert set(X_train.index).isdisjoint(set(X_valid.index))\n",
    "assert set(X_train.index).isdisjoint(set(X_test.index))\n",
    "assert set(X_valid.index).isdisjoint(set(X_test.index))\n",
    "assert df_fallos.loc[X_valid.index, \"failure\"].notna().all()\n",
    "assert df_fallos.loc[X_test.index, \"failure\"].notna().all()\n",
    "\n",
    "pd.Series({\n",
    "    \"train\": len(X_train),\n",
    "    \"valid\": len(X_valid),\n",
    "    \"test\": len(X_test)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d944a",
   "metadata": {},
   "source": [
    "Columnas inútiles, valores sin sentido y atípicos. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732590a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar id (identificador) y justificar\n",
    "X_train = X_train.drop(columns=['id'], errors='ignore')\n",
    "X_valid = X_valid.drop(columns=['id'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['id'], errors='ignore')\n",
    "X_unlabeled = X_unlabeled.drop(columns=['id'], errors='ignore')\n",
    "\n",
    "# Reglas de atipicos: definir SOLO con train si se aplican\n",
    "# En ausencia de criterio de negocio, se documenta que no se eliminan outliers.\n",
    "X_train.shape, X_valid.shape, X_test.shape, X_unlabeled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb34607",
   "metadata": {},
   "source": [
    "Tratamiento de valores nulos. 0.5 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab575481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputacion + OneHot + escalado (definir pipes, fit solo con train mas adelante)\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "df_fallos.isna().mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce237d",
   "metadata": {},
   "source": [
    "Análisis de variabilidad. 0.5 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis de baja varianza SOLO en numericas de train\n",
    "var_series = X_train[num_cols].var(numeric_only=True)\n",
    "low_var_cols = var_series[var_series < 1e-6].index.tolist()\n",
    "if low_var_cols:\n",
    "    X_train = X_train.drop(columns=low_var_cols)\n",
    "    X_valid = X_valid.drop(columns=low_var_cols)\n",
    "    X_test = X_test.drop(columns=low_var_cols)\n",
    "    X_unlabeled = X_unlabeled.drop(columns=low_var_cols)\n",
    "    num_cols = [c for c in num_cols if c not in low_var_cols]\n",
    "low_var_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a7a57",
   "metadata": {},
   "source": [
    "Columnas categóricas. 0.5 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85351f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SOLO con train y transform al resto\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_valid_proc = preprocessor.transform(X_valid)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "X_unlabeled_proc = preprocessor.transform(X_unlabeled)\n",
    "\n",
    "X_train_proc.shape, X_valid_proc.shape, X_test_proc.shape, X_unlabeled_proc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888f53a",
   "metadata": {},
   "source": [
    "Reducción de la dimensionalidad. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ff2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TruncatedSVD para salida sparse de OneHot\n",
    "max_components = max(2, min(100, X_train_proc.shape[1] - 1))\n",
    "svd = TruncatedSVD(n_components=max_components, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_proc)\n",
    "X_valid_svd = svd.transform(X_valid_proc)\n",
    "X_test_svd = svd.transform(X_test_proc)\n",
    "X_unlabeled_svd = svd.transform(X_unlabeled_proc)\n",
    "\n",
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a504b",
   "metadata": {},
   "source": [
    "Realiza un etiquetado automático. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1fa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-training iterativo con umbral 0.90\n",
    "threshold = 0.90\n",
    "max_iters = 10\n",
    "\n",
    "X_train_aug = pd.DataFrame(X_train_svd, index=X_train.index)\n",
    "y_train_aug = y_train.copy()\n",
    "\n",
    "X_unl = pd.DataFrame(X_unlabeled_svd, index=X_unlabeled.index)\n",
    "unlabeled_stats = []\n",
    "\n",
    "base_model = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "\n",
    "for it in range(1, max_iters + 1):\n",
    "    if X_unl.shape[0] == 0:\n",
    "        unlabeled_stats.append({\"iter\": it, \"added\": 0, \"remaining\": 0})\n",
    "        break\n",
    "    base_model.fit(X_train_aug, y_train_aug)\n",
    "    proba = base_model.predict_proba(X_unl)\n",
    "    max_proba = proba.max(axis=1)\n",
    "    pseudo_mask = max_proba >= threshold\n",
    "    added = int(pseudo_mask.sum())\n",
    "    remaining = int((~pseudo_mask).sum())\n",
    "    unlabeled_stats.append({\"iter\": it, \"added\": added, \"remaining\": remaining})\n",
    "    if added == 0:\n",
    "        break\n",
    "    y_pseudo = proba[pseudo_mask].argmax(axis=1)\n",
    "    X_train_aug = pd.concat([X_train_aug, X_unl[pseudo_mask]])\n",
    "    y_train_aug = pd.concat([y_train_aug, pd.Series(y_pseudo, index=X_unl[pseudo_mask].index)])\n",
    "    X_unl = X_unl.loc[~pseudo_mask]\n",
    "\n",
    "stats_df = pd.DataFrame(unlabeled_stats)\n",
    "stats_df\n",
    "\n",
    "plt.plot(stats_df[\"iter\"], stats_df[\"remaining\"])\n",
    "plt.title(\"Unlabeled restantes por iteracion\")\n",
    "plt.xlabel(\"Iteracion\")\n",
    "plt.ylabel(\"Remaining\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec91204d",
   "metadata": {},
   "source": [
    "Entrena y optimiza distintos modelos supervisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers de evaluacion en valid\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "X_valid_svd_df = pd.DataFrame(X_valid_svd, index=X_valid.index)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa4509",
   "metadata": {},
   "source": [
    "Modelo 1. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: LogisticRegression\n",
    "model1 = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "param_grid1 = {\n",
    "    \"C\": [0.1, 1.0, 10.0],\n",
    "    \"solver\": [\"liblinear\"]\n",
    "}\n",
    "grid1 = GridSearchCV(model1, param_grid1, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "grid1.fit(X_train_aug, y_train_aug)\n",
    "best1 = grid1.best_estimator_\n",
    "pred1 = best1.predict(X_valid_svd_df)\n",
    "metrics1 = eval_metrics(y_valid, pred1)\n",
    "grid1.best_params_, metrics1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b0160",
   "metadata": {},
   "source": [
    "Modelo 2. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59852c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2: RandomForest\n",
    "model2 = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "param_grid2 = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "grid2 = GridSearchCV(model2, param_grid2, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "grid2.fit(X_train_aug, y_train_aug)\n",
    "best2 = grid2.best_estimator_\n",
    "pred2 = best2.predict(X_valid_svd_df)\n",
    "metrics2 = eval_metrics(y_valid, pred2)\n",
    "grid2.best_params_, metrics2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000bfeb9",
   "metadata": {},
   "source": [
    "Modelo 3. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 3: SVC (probability=True para soft voting)\n",
    "model3 = SVC(probability=True, class_weight=\"balanced\")\n",
    "param_grid3 = {\n",
    "    \"C\": [0.5, 1.0, 2.0],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "grid3 = GridSearchCV(model3, param_grid3, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "grid3.fit(X_train_aug, y_train_aug)\n",
    "best3 = grid3.best_estimator_\n",
    "pred3 = best3.predict(X_valid_svd_df)\n",
    "metrics3 = eval_metrics(y_valid, pred3)\n",
    "grid3.best_params_, metrics3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f5374",
   "metadata": {},
   "source": [
    "Crea un modelo ensemble y explica el criterio que utilizas. 1 punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b856792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesos basados en f1 de valid (normalizados)\n",
    "f1_scores = np.array([metrics1[\"f1\"], metrics2[\"f1\"], metrics3[\"f1\"]])\n",
    "weights = (f1_scores / f1_scores.sum()).tolist() if f1_scores.sum() > 0 else [1, 1, 1]\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"lr\", best1), (\"rf\", best2), (\"svc\", best3)],\n",
    "    voting=\"soft\",\n",
    "    weights=weights\n",
    ")\n",
    "ensemble.fit(X_train_aug, y_train_aug)\n",
    "valid_pred = ensemble.predict(X_valid_svd_df)\n",
    "ensemble_metrics = eval_metrics(y_valid, valid_pred)\n",
    "weights, ensemble_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluacion final SOLO en test (una vez al final)\n",
    "X_test_svd_df = pd.DataFrame(X_test_svd, index=X_test.index)\n",
    "test_pred = ensemble.predict(X_test_svd_df)\n",
    "print(classification_report(y_test, test_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, test_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10a107",
   "metadata": {},
   "source": [
    "Por completar tras ejecutar: accuracy, f1, balanced_accuracy, matriz de confusión y conclusión final."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
